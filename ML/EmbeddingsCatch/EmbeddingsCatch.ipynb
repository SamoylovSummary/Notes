{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По мотивам \"Чудесный мир Word Embeddings: какие они бывают и зачем нужны?\"\n",
    "\n",
    "https://habrahabr.ru/company/ods/blog/329410/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21668</th>\n",
       "      <td>21669</td>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54842</th>\n",
       "      <td>54843</td>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2013-01-12 09:07:07</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77291</th>\n",
       "      <td>77292</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:14</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>784.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114020</th>\n",
       "      <td>114021</td>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>945.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146669</th>\n",
       "      <td>146670</td>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>950.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>950.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        session_id  site1               time1  site2               time2  \\\n",
       "21668        21669     56 2013-01-12 08:05:57   55.0 2013-01-12 08:05:57   \n",
       "54842        54843     56 2013-01-12 08:37:23   55.0 2013-01-12 08:37:23   \n",
       "77291        77292    946 2013-01-12 08:50:13  946.0 2013-01-12 08:50:14   \n",
       "114020      114021    945 2013-01-12 08:50:17  948.0 2013-01-12 08:50:17   \n",
       "146669      146670    947 2013-01-12 08:50:20  950.0 2013-01-12 08:50:20   \n",
       "\n",
       "        site3               time3  site4               time4  site5   ...    \\\n",
       "21668     NaN                 NaT    NaN                 NaT    NaN   ...     \n",
       "54842    56.0 2013-01-12 09:07:07   55.0 2013-01-12 09:07:09    NaN   ...     \n",
       "77291   951.0 2013-01-12 08:50:15  946.0 2013-01-12 08:50:15  946.0   ...     \n",
       "114020  949.0 2013-01-12 08:50:18  948.0 2013-01-12 08:50:18  945.0   ...     \n",
       "146669  948.0 2013-01-12 08:50:20  947.0 2013-01-12 08:50:21  950.0   ...     \n",
       "\n",
       "                     time6  site7               time7  site8  \\\n",
       "21668                  NaT    NaN                 NaT    NaN   \n",
       "54842                  NaT    NaN                 NaT    NaN   \n",
       "77291  2013-01-12 08:50:16  948.0 2013-01-12 08:50:16  784.0   \n",
       "114020 2013-01-12 08:50:18  947.0 2013-01-12 08:50:19  945.0   \n",
       "146669 2013-01-12 08:50:21  946.0 2013-01-12 08:50:21  951.0   \n",
       "\n",
       "                     time8  site9               time9  site10  \\\n",
       "21668                  NaT    NaN                 NaT     NaN   \n",
       "54842                  NaT    NaN                 NaT     NaN   \n",
       "77291  2013-01-12 08:50:16  949.0 2013-01-12 08:50:17   946.0   \n",
       "114020 2013-01-12 08:50:19  946.0 2013-01-12 08:50:19   946.0   \n",
       "146669 2013-01-12 08:50:22  946.0 2013-01-12 08:50:22   947.0   \n",
       "\n",
       "                    time10  target  \n",
       "21668                  NaT       0  \n",
       "54842                  NaT       0  \n",
       "77291  2013-01-12 08:50:17       0  \n",
       "114020 2013-01-12 08:50:20       0  \n",
       "146669 2013-01-12 08:50:22       0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузим обучающую и тестовую выборки\n",
    "train_df = pd.read_csv('data/train_sessions.csv')\n",
    "test_df = pd.read_csv('data/test_sessions.csv')\n",
    "\n",
    "# приведем колонки time1, ..., time10 к временному формату\n",
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "train_df[times] = train_df[times].apply(pd.to_datetime)\n",
    "test_df[times] = test_df[times].apply(pd.to_datetime)\n",
    "\n",
    "# отсортируем данные по времени\n",
    "train_df = train_df.sort_values(by='time1')\n",
    "\n",
    "# посмотрим на заголовок обучающей выборки\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21668</th>\n",
       "      <td>21669</td>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>55</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54842</th>\n",
       "      <td>54843</td>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>55</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 09:07:07</td>\n",
       "      <td>55</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77291</th>\n",
       "      <td>77292</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:14</td>\n",
       "      <td>951</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>948</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>784</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>949</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114020</th>\n",
       "      <td>114021</td>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>948</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>949</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>948</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>945</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146669</th>\n",
       "      <td>146670</td>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>950</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>948</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>950</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>951</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        session_id site1               time1 site2               time2 site3  \\\n",
       "21668        21669    56 2013-01-12 08:05:57    55 2013-01-12 08:05:57     0   \n",
       "54842        54843    56 2013-01-12 08:37:23    55 2013-01-12 08:37:23    56   \n",
       "77291        77292   946 2013-01-12 08:50:13   946 2013-01-12 08:50:14   951   \n",
       "114020      114021   945 2013-01-12 08:50:17   948 2013-01-12 08:50:17   949   \n",
       "146669      146670   947 2013-01-12 08:50:20   950 2013-01-12 08:50:20   948   \n",
       "\n",
       "                     time3 site4               time4 site5  ...    \\\n",
       "21668                  NaT     0                 NaT     0  ...     \n",
       "54842  2013-01-12 09:07:07    55 2013-01-12 09:07:09     0  ...     \n",
       "77291  2013-01-12 08:50:15   946 2013-01-12 08:50:15   946  ...     \n",
       "114020 2013-01-12 08:50:18   948 2013-01-12 08:50:18   945  ...     \n",
       "146669 2013-01-12 08:50:20   947 2013-01-12 08:50:21   950  ...     \n",
       "\n",
       "                     time6 site7               time7 site8  \\\n",
       "21668                  NaT     0                 NaT     0   \n",
       "54842                  NaT     0                 NaT     0   \n",
       "77291  2013-01-12 08:50:16   948 2013-01-12 08:50:16   784   \n",
       "114020 2013-01-12 08:50:18   947 2013-01-12 08:50:19   945   \n",
       "146669 2013-01-12 08:50:21   946 2013-01-12 08:50:21   951   \n",
       "\n",
       "                     time8 site9               time9 site10  \\\n",
       "21668                  NaT     0                 NaT      0   \n",
       "54842                  NaT     0                 NaT      0   \n",
       "77291  2013-01-12 08:50:16   949 2013-01-12 08:50:17    946   \n",
       "114020 2013-01-12 08:50:19   946 2013-01-12 08:50:19    946   \n",
       "146669 2013-01-12 08:50:22   946 2013-01-12 08:50:22    947   \n",
       "\n",
       "                    time10 target  \n",
       "21668                  NaT      0  \n",
       "54842                  NaT      0  \n",
       "77291  2013-01-12 08:50:17      0  \n",
       "114020 2013-01-12 08:50:20      0  \n",
       "146669 2013-01-12 08:50:22      0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "\n",
    "#заменим nan на 0\n",
    "train_df[sites] = train_df[sites].fillna(0).astype('int').astype('str')\n",
    "test_df[sites] = test_df[sites].fillna(0).astype('int').astype('str')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['229', '1500', '33', '1500', '391', '35', '29', '2276', '40305', '23']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#создадим тексты необходимые для обучения word2vec\n",
    "def append_sentence(data):\n",
    "    data['list'] = data['site1']\n",
    "    for s in sites[1:]:\n",
    "        data['list'] = data['list'] + \",\" + data[s]\n",
    "    data['list_w'] = data['list'].apply(lambda x: x.split(','))\n",
    "\n",
    "append_sentence(train_df)\n",
    "append_sentence(test_df)\n",
    "\n",
    "#В нашем случае предложение это набор сайтов, которые посещал пользователь\n",
    "#нам необязательно переводить цифры в названия сайтов, т.к. алгоритм будем выявлять взаимосвязь их друг с другом.\n",
    "train_df['list_w'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# подключим word2vec\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# обучим нашу модель на всех данных с размером окна в 6=3*2 (длина предложения 10 слов) \n",
    "#и итоговыми векторами размерности 300, параметр workers отвечает за количество ядер\n",
    "\n",
    "w2v_dim = 300\n",
    "\n",
    "w2v_model = word2vec.Word2Vec(train_df['list_w'], size=w2v_dim, window=3, workers=4)\n",
    "\n",
    "#создадим словарь со словами и соответсвующими им векторами\n",
    "w2v_dict = dict(zip(w2v_model.wv.index2word, w2v_model.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253561, 300)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentence_to_vector(sentence):\n",
    "    return np.array([\n",
    "        np.mean([w2v_dict[w] for w in words if w in w2v_dict] or [np.zeros(w2v_dim)], axis=0)\n",
    "        for words in sentence\n",
    "    ])\n",
    "\n",
    "x_all = sentence_to_vector(train_df['list_w'])\n",
    "\n",
    "x_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((202849, 300), (50712, 300), 0.009726446765820882, 0.006389020350212968)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Воспользуемся валидацией\n",
    "def split(x, y, ratio):\n",
    "    pos = round(x.shape[0] * ratio)\n",
    "    return x[:pos, :], x[pos:, :], y[:pos], y[pos:]\n",
    "\n",
    "y_all = train_df['target']\n",
    "x_tr, x_val, y_tr, y_val = split(x_all, y_all, 0.8)\n",
    "x_tr.shape, x_val.shape, y_tr.mean(), y_val.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# подключим библиотеки keras \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# опишем нейронную сеть\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=(x_tr.shape[1])))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "202849/202849 [==============================] - 3s - loss: 0.0497 - binary_accuracy: 0.9900     \n",
      "Epoch 2/3\n",
      "202849/202849 [==============================] - 3s - loss: 0.0440 - binary_accuracy: 0.9903     \n",
      "Epoch 3/3\n",
      "202849/202849 [==============================] - 3s - loss: 0.0426 - binary_accuracy: 0.9904     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9037987439690226"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(x_tr, y_tr,\n",
    "        batch_size=128,\n",
    "        epochs=3,\n",
    "        class_weight='auto')\n",
    "\n",
    "classes = model.predict(x_val, batch_size=128)\n",
    "roc_auc_score(y_val, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(324, 50388)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_yes = [x for x in y_val if x > 0.5]\n",
    "y_no = [x for x in y_val if x <= 0.5]\n",
    "len(y_yes), len(y_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50711)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_yes = [x[0] for x in classes if x[0] > 0.5]\n",
    "c_no = [x[0] for x in classes if x[0] <= 0.5]\n",
    "len(c_yes), len(c_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.853648\teval-auc:0.829728\n",
      "[20]\ttrain-auc:0.920121\teval-auc:0.90519\n",
      "[40]\ttrain-auc:0.928887\teval-auc:0.910065\n",
      "[60]\ttrain-auc:0.93511\teval-auc:0.909688\n",
      "[80]\ttrain-auc:0.942525\teval-auc:0.912934\n",
      "[100]\ttrain-auc:0.949274\teval-auc:0.913217\n",
      "[120]\ttrain-auc:0.954374\teval-auc:0.91444\n",
      "[140]\ttrain-auc:0.958278\teval-auc:0.913285\n",
      "[160]\ttrain-auc:0.96174\teval-auc:0.913222\n",
      "[180]\ttrain-auc:0.964827\teval-auc:0.913881\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "d_tr = xgb.DMatrix(x_tr, label=y_tr, missing=np.nan)\n",
    "d_val = xgb.DMatrix(x_val, label=y_val, missing=np.nan)\n",
    "watchlist = [(d_tr, 'train'), (d_val, 'eval')]\n",
    "history = dict()\n",
    "\n",
    "params = {\n",
    "    'max_depth': 5,\n",
    "    'eta': 0.05,\n",
    "    'nthread': 4,\n",
    "    'gamma' : 1,\n",
    "    'alpha' : 1,\n",
    "    'subsample': 0.2,\n",
    "    'eval_metric': ['auc'],\n",
    "    'objective': 'binary:logistic',\n",
    "    'colsample_bytree': 0.9,\n",
    "    'min_child_weight': 100,\n",
    "    'scale_pos_weight':(1)/y_all.mean(),\n",
    "    'seed':7\n",
    "}\n",
    "\n",
    "model_new = xgb.train(params, d_tr, num_boost_round=200, evals=watchlist, evals_result=history, verbose_eval=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89583281268222792"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# обучение классификатора\n",
    "lr = LogisticRegression(C=1, random_state=7).fit(x_tr, y_tr)\n",
    "# прогноз для валидационной выборки\n",
    "y_pred = lr.predict_proba(x_val)[:, 1]\n",
    "# считаем качество\n",
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#пропишем класс выполняющий tfidf преобразование.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import defaultdict\n",
    "\n",
    "class tfidf_vectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(next(iter(word2vec.values())))\n",
    "\n",
    "    def fit(self, X):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf,\n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])\n",
    "\n",
    "x_all = tfidf_vectorizer(w2v_dict).fit(train_df['list_w']).transform(train_df['list_w'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
